ะัััั ะฟะพ ะฟัะพะตะบัั: ะกัะฐะฒะฝะตะฝะธะต ะผะพะดะตะปะตะน ะดะปั ะฐะฝะฐะปะธะทะฐ ัะพะฝะฐะปัะฝะพััะธ ัะตะบััะฐ
๐ฏ ะฆะตะปั ะฟัะพะตะบัะฐ

ะกัะฐะฒะฝะตะฝะธะต ัะฐะทะปะธัะฝัั ะฟะพะดัะพะดะพะฒ (ะบะปะฐััะธัะธะบะฐัะพัั vs ะณะตะฝะตัะฐัะธะฒะฝัะต ะผะพะดะตะปะธ) ะดะปั ะทะฐะดะฐัะธ ะฐะฝะฐะปะธะทะฐ ัะพะฝะฐะปัะฝะพััะธ ัะตะบััะฐ ะฝะฐ ััััะบะพะผ ัะทัะบะต. ะัะพะฒะตะดะตะฝะธะต ัะบัะฟะตัะธะผะตะฝัะพะฒ ะฟะพ ะฒะปะธัะฝะธั ัะพัะผะฐัะฐ ะฟัะพะผะฟัะพะฒ, ัะตะผะฟะตัะฐัััั ะณะตะฝะตัะฐัะธะธ ะธ ัััะฐัะตะณะธะธ ะพะฑััะตะฝะธั (zero-shot vs few-shot).
๐ ะะฐัะฐัะตั

RuSentiment - ะดะฐัะฐัะตั ะดะปั ะฐะฝะฐะปะธะทะฐ ัะพะฝะฐะปัะฝะพััะธ ััััะบะธั ัะตะบััะพะฒ:
    ะขัะตะฝะธัะพะฒะพัะฝะฐั ะฒัะฑะพัะบะฐ: 4,649 ะฟัะธะผะตัะพะฒ
    ะขะตััะพะฒะฐั ะฒัะฑะพัะบะฐ: 1,163 ะฟัะธะผะตัะพะฒ
    3 ะบะปะฐััะฐ: negative (ะฝะตะณะฐัะธะฒะฝัะน), neutral (ะฝะตะนััะฐะปัะฝัะน), positive (ะฟะพะทะธัะธะฒะฝัะน)
    ะะฐัะฟัะตะดะตะปะตะฝะธะต ะบะปะฐััะพะฒ:
        neutral: 2,370 (51.0%)
        positive: 1,196 (25.7%)
        negative: 1,083 (23.3%)

๐ค ะะพะดะตะปะธ
1. ะะปะฐััะธัะธะบะฐัะพัั (Fine-tuned)
ะะพะดะตะปั	ะะฐัะฐะผะตััั	ะะฐะทะผะตั	ะขะธะฟ	ะะฟะธัะฐะฝะธะต
cointegrated/rubert-tiny2	84M	118MB	ะะปะฐััะธัะธะบะฐัะพั	ะะพะผะฟะฐะบัะฝะฐั ะผะพะดะตะปั, ะฑััััะฐั ะธะฝัะตัะตะฝั
blanchefort/rubert-base-cased-sentiment-rusentiment	178M	~500MB	ะะปะฐััะธัะธะบะฐัะพั	ะกะฟะตัะธะฐะปะธะทะธัะพะฒะฐะฝะฝะฐั ะดะปั ะฐะฝะฐะปะธะทะฐ ัะพะฝะฐะปัะฝะพััะธ
2. ะะตะฝะตัะฐัะธะฒะฝะฐั ะผะพะดะตะปั
ะะพะดะตะปั	ะะฐัะฐะผะตััั	ะะฐะทะผะตั	ะขะธะฟ	ะะฟะธัะฐะฝะธะต
ai-forever/rugpt3small_based_on_gpt2	125M	551MB	ะะตะฝะตัะฐัะธะฒะฝะฐั	ะัััะบะฐั GPT-2 ะดะปั ัะตะบััะพะฒะพะน ะณะตะฝะตัะฐัะธะธ
๐ ะะตััะธะบะธ ะพัะตะฝะบะธ
ะะฑัะทะฐัะตะปัะฝัะต ะผะตััะธะบะธ:
    Accuracy - ะพะฑัะฐั ัะพัะฝะพััั ะบะปะฐััะธัะธะบะฐัะธะธ
    Precision/Recall/F1-score - ะฟะพ ะบะปะฐััะฐะผ ะธ ัััะตะดะฝัะฝะฝัะต
    Confusion Matrix - ะผะฐััะธัะฐ ะพัะธะฑะพะบ
    Inference Time - ะฒัะตะผั ะธะฝัะตัะตะฝัะฐ ะฝะฐ ะฟัะธะผะตั
    Text Length - ััะตะดะฝัั ะดะปะธะฝะฐ ะพะฑัะฐะฑะฐััะฒะฐะตะผะพะณะพ ัะตะบััะฐ
ะญะบัะฟะตัะธะผะตะฝัะฐะปัะฝัะต ะผะตััะธะบะธ (GPT-2):
    Prompt Template Effectiveness - ัััะตะบัะธะฒะฝะพััั ัะฐะทะฝัั ัะพัะผะฐัะพะฒ ะฟัะพะผะฟัะพะฒ
    Temperature Impact - ะฒะปะธัะฝะธะต ัะตะผะฟะตัะฐัััั ะฝะฐ ะบะฐัะตััะฒะพ ะณะตะฝะตัะฐัะธะธ
    Zero-shot vs Few-shot - ััะฐะฒะฝะตะฝะธะต ัััะฐัะตะณะธะน ะฟัะพะผะฟัะธะฝะณะฐ
    Response Length - ะดะปะธะฝะฐ ัะณะตะฝะตัะธัะพะฒะฐะฝะฝัั ะพัะฒะตัะพะฒ
๐ ะะตะทัะปััะฐัั
1. RuBERT-tiny2 (ะฑะฐะทะพะฒัะน ะบะปะฐััะธัะธะบะฐัะพั)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ            RuBERT-tiny2 (84M params)         โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโฃ
โ Accuracy:       34.00%                       โ
โ Precision:      37.56%                       โ
โ Recall:         34.00%                       โ
โ F1-score:       30.07%                       โ
โ Inference time: 0.0024 ัะตะบ (ัะฐะผัะน ะฑัััััะน)   โ
โ Avg text length: 67.39 ัะธะผะฒะพะปะพะฒ              โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

Confusion Matrix:
[[ 3  1 15]   โ negative
 [13  8 28]   โ neutral  
 [ 1  8 23]]  โ positive

Classification Report:
              precision    recall  f1-score   support
    negative       0.18      0.16      0.17        19
     neutral       0.47      0.16      0.24        49
    positive       0.35      0.72      0.47        32
    accuracy                           0.34       100

ะะฝะฐะปะธะท:
    ะะธะทะบะฐั ัะพัะฝะพััั (34%), ะฝะพ ะพัะตะฝั ะฒััะพะบะฐั ัะบะพัะพััั
    ะกะธะปัะฝัะน bias ะฒ ััะพัะพะฝั ะบะปะฐััะฐ "positive" (recall 72%)
    ะะปะพัะพ ัะฐะทะปะธัะฐะตั negative ะธ neutral ะบะปะฐััั
2. RuBERT-base-sentiment (ัะฟะตัะธะฐะปะธะทะธัะพะฒะฐะฝะฝัะน ะบะปะฐััะธัะธะบะฐัะพั)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ     RuBERT-base-sentiment (178M params)      โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโฃ
โ Accuracy:       85.00%  (ะฝะฐะธะปัััะธะน ัะตะทัะปััะฐั)โ
โ Precision:      85.54%                       โ
โ Recall:         85.00%                       โ
โ F1-score:       85.07%                       โ
โ Inference time: 0.0321 ัะตะบ                   โ
โ Avg text length: 67.39 ัะธะผะฒะพะปะพะฒ              โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

Confusion Matrix:
[[14  5  0]   โ negative
 [ 4 44  1]   โ neutral  
 [ 1  4 27]]  โ positive

Classification Report:
              precision    recall  f1-score   support
    negative       0.74      0.74      0.74        19
     neutral       0.83      0.90      0.86        49
    positive       0.96      0.84      0.90        32
    accuracy                           0.85       100

ะะฝะฐะปะธะท:
    ะัะปะธัะฝัะต ัะตะทัะปััะฐัั ะฟะพ ะฒัะตะผ ะผะตััะธะบะฐะผ (85% accuracy)
    ะกะฑะฐะปะฐะฝัะธัะพะฒะฐะฝะฝะฐั ัะพัะฝะพััั ะฟะพ ะฒัะตะผ ะบะปะฐััะฐะผ
    ะฅะพัะพัะพ ัะฐะทะปะธัะฐะตั ะฒัะต ััะธ ะบะปะฐััะฐ ัะพะฝะฐะปัะฝะพััะธ
    ะะฟัะธะผะฐะปัะฝัะน ะฑะฐะปะฐะฝั ัะบะพัะพััะธ ะธ ะบะฐัะตััะฒะฐ
3. GPT-2 (ะณะตะฝะตัะฐัะธะฒะฝะฐั ะผะพะดะตะปั)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ           GPT-2 (125M params)                โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโฃ
โ Accuracy:       30.0%                        โ
โ Inference time: 0.322 ัะตะบ (ัะฐะผัะน ะผะตะดะปะตะฝะฝัะน)  โ
โ Response length: 50.0 ัะธะผะฒะพะปะพะฒ               โ
โ Best template: Few-shot (40% ะฝะฐ ะผะฐะปะพะน ะฒัะฑะพัะบะต)โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

Confusion Matrix (ะพัะฝะพะฒะฝะฐั ะฟัะพะฑะปะตะผะฐ):
[[0 0 0]   โ negative (ะฒัะต ะพัะธะฑะบะธ)
 [0 0 7]   โ neutral  (ะฒัะต ะพัะธะฑะบะธ)
 [0 0 6]]  โ positive (ะฒัะต ะฟัะฐะฒะธะปัะฝัะต)

Classification Report:
              precision    recall  f1-score   support
    negative       0.00      0.00      0.00         7
     neutral       0.00      0.00      0.00         7  
    positive       0.30      1.00      0.46         6

ะะปััะตะฒะฐั ะฟัะพะฑะปะตะผะฐ: rugpt3small ัะปะธัะบะพะผ ะผะฐะปะตะฝัะบะฐั ะผะพะดะตะปั 
๐ฌ ะญะบัะฟะตัะธะผะตะฝัั ั GPT-2
๐ ะญะบัะฟะตัะธะผะตะฝั 1: ะะปะธัะฝะธะต ัะพัะผะฐัะฐ ะฟัะพะผะฟัะฐ
ะจะฐะฑะปะพะฝ ะฟัะพะผะฟัะฐ	Accuracy	ะัะตะผั (ัะตะบ)	ะะฟะธัะฐะฝะธะต	ะัะพะฑะปะตะผั
short	0.0%	0.254	ัะพะฝะฐะปัะฝะพััั: {ัะตะบัั}	ะกะปะธัะบะพะผ ะบัะฐัะบะพ, ะผะพะดะตะปั ะฝะต ะฟะพะฝะธะผะฐะตั ะทะฐะดะฐัั
medium	0.0%	0.251	ะพะฟัะตะดะตะปะธัั ัะพะฝะฐะปัะฝะพััั ัะตะบััะฐ: {ัะตะบัั}	ะะตะดะพััะฐัะพัะฝะพ ะบะพะฝัะตะบััะฐ
long	10.0%	0.268	ะะพะดัะพะฑะฝะพะต ะพะฟะธัะฐะฝะธะต ะทะฐะดะฐัะธ	ะัััะต, ะฝะพ ะฒัั ัะฐะฒะฝะพ ะฝะธะทะบะฐั ัะพัะฝะพััั
few_shot	40.0%	0.326	ะัะธะผะตัั ั ะฟัะฐะฒะธะปัะฝัะผะธ ะพัะฒะตัะฐะผะธ	ะะฐะธะปัััะธะน ัะตะทัะปััะฐั

ะัะฒะพะด: Few-shot ะฟัะพะผะฟัะธะฝะณ ัััะตััะฒะตะฝะฝะพ ัะปัััะฐะตั ะบะฐัะตััะฒะพ ะณะตะฝะตัะฐัะธะฒะฝัั ะผะพะดะตะปะตะน.
๐ก๏ธ ะญะบัะฟะตัะธะผะตะฝั 2: ะะปะธัะฝะธะต ัะตะผะฟะตัะฐัััั ะณะตะฝะตัะฐัะธะธ
ะขะตะผะฟะตัะฐัััะฐ	Accuracy	ะฃะฝะธะบะฐะปัะฝัะต ะพัะฒะตัั	ะะพะฝัะธััะตะฝัะฝะพััั
0.1	20.0%	{unknown, ะฟะพะทะธัะธะฒะฝัะน}	ะััะพะบะฐั
0.7	20.0%	{unknown, ะฟะพะทะธัะธะฒะฝัะน}	ะกัะตะดะฝัั
1.2	20.0%	{unknown, ะฟะพะทะธัะธะฒะฝัะน}	ะะธะทะบะฐั

ะัะฒะพะด: ะขะตะผะฟะตัะฐัััะฐ ะฝะต ะพะบะฐะทัะฒะฐะตั ะทะฝะฐัะธัะตะปัะฝะพะณะพ ะฒะปะธัะฝะธั ะฝะฐ accuracy, ะฝะพ ะฒะปะธัะตั ะฝะฐ ัะฐะทะฝะพะพะฑัะฐะทะธะต ะพัะฒะตัะพะฒ.
๐ฏ ะญะบัะฟะตัะธะผะตะฝั 3: Zero-shot vs Few-shot
ะกััะฐัะตะณะธั	Accuracy	ะัะตะผั (ัะตะบ)	ะัะตะธะผััะตััะฒะฐ	ะะตะดะพััะฐัะบะธ
Zero-shot	0.0%	0.256	ะัะพััะฐั ะฝะฐัััะพะนะบะฐ	ะัะตะฝั ะฝะธะทะบะพะต ะบะฐัะตััะฒะพ
Few-shot	37.5%	0.337	ะะฝะฐัะธัะตะปัะฝะพ ะปัััะตะต ะบะฐัะตััะฒะพ	ะขัะตะฑัะตั ะฟัะธะผะตัะพะฒ, ะผะตะดะปะตะฝะฝะตะต

ะัะฒะพะด: Few-shot ัััะฐัะตะณะธั ะพะฑัะทะฐัะตะปัะฝะฐ ะดะปั ะธัะฟะพะปัะทะพะฒะฐะฝะธั ะณะตะฝะตัะฐัะธะฒะฝัั ะผะพะดะตะปะตะน ะฒ ะทะฐะดะฐัะฐั ะบะปะฐััะธัะธะบะฐัะธะธ.
ะะฝะฐะปะธะท ะพัะธะฑะพะบ GPT-2
    ะัะตะณะพ ะพัะธะฑะพะบ: 14 ะธะท 20 (70.0%)
    ะัะฝะพะฒะฝะฐั ะฟัะพะฑะปะตะผะฐ: ะกะบะปะพะฝะฝะพััั ะบ ะบะปะฐััั "positive"

ะกัะฐะฒะฝะธัะตะปัะฝัะน ะฐะฝะฐะปะธะท ะผะพะดะตะปะตะน
ะกะฒะพะดะฝะฐั ัะฐะฑะปะธัะฐ ะฟัะพะธะทะฒะพะดะธัะตะปัะฝะพััะธ
ะะพะดะตะปั	Accuracy	Inference Time	ะะฐัะฐะผะตััั	ะัััะตะต ะฟัะธะผะตะฝะตะฝะธะต
RuBERT-tiny2	34%	0.002 ัะตะบ โก	84M	ะกะบะพัะพััั-ะบัะธัะธัะฝัะต ะฟัะธะปะพะถะตะฝะธั
RuBERT-base-sentiment	85% ๐	0.032 ัะตะบ	178M	Production ัะธััะตะผั
GPT-2 (few-shot)	30-40%	0.322 ัะตะบ ๐	125M	ะญะบัะฟะตัะธะผะตะฝัั, ะธััะปะตะดะพะฒะฐะฝะธั

ะะธะทัะฐะปะธะทะฐัะธั trade-off (ะขะพัะฝะพััั vs ะกะบะพัะพััั)
Accuracy (%)     ะกะบะพัะพััั (ัะตะบ)
    โฒ              โฒ
    โ              โ
 85 โโโโ           โ
    โ   โ          โ
    โ     โ        โ
 50 โ       โ      โ
    โ         โ    โ
    โ           โ  โ
 30 โ             โโ
    โโโโโโโโโโโโโโโโดโโโโโโโโโโโโบ
    0.002    0.032    0.322

ะะปััะตะฒัะต ัะฐะทะปะธัะธั ะฐััะธัะตะบััั
ะัะฟะตะบั	ะะปะฐััะธัะธะบะฐัะพัั	ะะตะฝะตัะฐัะธะฒะฝัะต ะผะพะดะตะปะธ
ะััะธัะตะบัััะฐ	Encoder-only (BERT)	Decoder-only (GPT)
ะะฐะดะฐัะฐ	ะะปะฐััะธัะธะบะฐัะธั	ะขะตะบััะพะฒะฐั ะณะตะฝะตัะฐัะธั
ะััะพะด	ะะตัะพััะฝะพััะธ ะบะปะฐััะพะฒ	ะะพัะปะตะดะพะฒะฐัะตะปัะฝะพััั ัะพะบะตะฝะพะฒ
ะขัะตะฑัะตั	Fine-tuning	Prompt engineering
ะกะบะพัะพััั	ะััะพะบะฐั	ะะธะทะบะฐั
ะขะพัะฝะพััั	ะััะพะบะฐั	ะะธะทะบะฐั-ััะตะดะฝัั

ะัะฒะพะดั
1. ะััะธัะตะบัััะฝัะต ะฟัะตะธะผััะตััะฒะฐ
    ะะปะฐััะธัะธะบะฐัะพัั ัััะตััะฒะตะฝะฝะพ ะฟัะตะฒะพััะพะดัั ะณะตะฝะตัะฐัะธะฒะฝัะต ะผะพะดะตะปะธ ะดะปั ะทะฐะดะฐั ะบะฐัะตะณะพัะธะทะฐัะธะธ
    Fine-tuning ะฝะฐ ัะตะปะตะฒะพะน ะทะฐะดะฐัะต ะบัะธัะธัะตัะบะธ ะฒะฐะถะตะฝ ะดะปั ะบะฐัะตััะฒะฐ
    ะกะฟะตัะธะฐะปะธะทะธัะพะฒะฐะฝะฝัะต ะผะพะดะตะปะธ (rubert-base-sentiment) ะฟะพะบะฐะทัะฒะฐัั ะฝะฐะธะปัััะธะต ัะตะทัะปััะฐัั
2. ะญััะตะบัะธะฒะฝะพััั ะฟัะพะผะฟัะธะฝะณะฐ
    Few-shot ะฟัะพะผะฟัะธะฝะณ ัะปัััะฐะตั ะณะตะฝะตัะฐัะธะฒะฝัะต ะผะพะดะตะปะธ ะฝะฐ 40%+
    ะะฐัะตััะฒะพ ะฟัะพะผะฟัะพะฒ ัะธะปัะฝะพ ะฒะปะธัะตั ะฝะฐ ัะตะทัะปััะฐัั GPT-2
    ะขะตะผะฟะตัะฐัััะฐ ะผะฐะปะพ ะฒะปะธัะตั ะฝะฐ accuracy, ะฝะพ ัะตะณัะปะธััะตั ัะฐะทะฝะพะพะฑัะฐะทะธะต
3. ะัะพะธะทะฒะพะดะธัะตะปัะฝะพััั
    RuBERT-tiny2 ะฒ 161 ัะฐะท ะฑััััะตะต GPT-2 (0.002ั vs 0.322ั)
    RuBERT-base ะฒ 10 ัะฐะท ะฑััััะตะต GPT-2 ะฟัะธ ะทะฝะฐัะธัะตะปัะฝะพ ะปัััะตะผ ะบะฐัะตััะฒะต
    ะะตะฝะตัะฐัะธะฒะฝัะต ะผะพะดะตะปะธ ะฝะตะฟัะฐะบัะธัะฝั ะดะปั real-time ะฟัะธะปะพะถะตะฝะธะน
4. ะะฐัะตััะฒะพ ะบะปะฐััะธัะธะบะฐัะธะธ
    ะกะฟะตัะธะฐะปะธะทะธัะพะฒะฐะฝะฝัะต ะบะปะฐััะธัะธะบะฐัะพัั ะดะพััะธะณะฐัั 85% accuracy
    ะะตะฝะตัะฐัะธะฒะฝัะต ะผะพะดะตะปะธ ัััะฐะดะฐัั ะพั bias (ัะบะปะพะฝะฝะพััั ะบ "positive")
    ะะฐะทะปะธัะตะฝะธะต negative/neutral - ัะฐะผะฐั ัะปะพะถะฝะฐั ะทะฐะดะฐัะฐ ะดะปั ะฒัะตั ะผะพะดะตะปะตะน
 ะขะตัะฝะพะปะพะณะธัะตัะบะธะน ััะตะบ
    Python 3.12 - ะพัะฝะพะฒะฝะพะน ัะทัะบ ัะฐะทัะฐะฑะพัะบะธ
    PyTorch 2.2.2 - ััะตะนะผะฒะพัะบ ะดะปั ะณะปัะฑะพะบะพะณะพ ะพะฑััะตะฝะธั
    Transformers 4.38.0 - ะฑะธะฑะปะธะพัะตะบะฐ ะดะปั NLP ะผะพะดะตะปะตะน
    Scikit-learn 1.4.0 - ะผะตััะธะบะธ ะธ ะพัะตะฝะบะฐ ะผะพะดะตะปะตะน
    Pandas 2.2.0 - ะพะฑัะฐะฑะพัะบะฐ ะดะฐะฝะฝัั
    Matplotlib/Seaborn - ะฒะธะทัะฐะปะธะทะฐัะธั ัะตะทัะปััะฐัะพะฒ

ะัััััะน ััะฐัั

# 1. ะะปะพะฝะธัะพะฒะฐะฝะธะต ะธ ัััะฐะฝะพะฒะบะฐ
git clone <repository-url>
cd LLM_metrics
pip install -r requirements.txt
# 2. ะะฐะฟััะบ ััะฐะฒะฝะตะฝะธั ะบะปะฐััะธัะธะบะฐัะพัะพะฒ
python sentiment_metrics.py
# 3. ะะฐะฟััะบ ัะบัะฟะตัะธะผะตะฝัะพะฒ ั GPT-2
python generative_experiments.py
